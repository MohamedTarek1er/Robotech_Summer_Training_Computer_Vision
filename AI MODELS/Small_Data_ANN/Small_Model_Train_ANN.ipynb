{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 'A': 100%|██████████| 900/900 [00:37<00:00, 24.24it/s]\n",
      "Processing 'B': 100%|██████████| 900/900 [00:35<00:00, 25.60it/s]\n",
      "Processing 'BLANK': 100%|██████████| 900/900 [00:24<00:00, 36.71it/s]\n",
      "Processing 'C': 100%|██████████| 900/900 [00:35<00:00, 25.35it/s]\n",
      "Processing 'D': 100%|██████████| 900/900 [00:33<00:00, 26.66it/s]\n",
      "Processing 'E': 100%|██████████| 900/900 [00:30<00:00, 29.75it/s]\n",
      "Processing 'F': 100%|██████████| 900/900 [00:42<00:00, 21.19it/s]\n",
      "Processing 'G': 100%|██████████| 900/900 [00:37<00:00, 23.97it/s]\n",
      "Processing 'H': 100%|██████████| 900/900 [00:35<00:00, 25.59it/s]\n",
      "Processing 'I': 100%|██████████| 900/900 [00:37<00:00, 23.98it/s]\n",
      "Processing 'J': 100%|██████████| 900/900 [00:29<00:00, 30.33it/s]\n",
      "Processing 'K': 100%|██████████| 900/900 [00:30<00:00, 29.19it/s]\n",
      "Processing 'L': 100%|██████████| 900/900 [00:31<00:00, 28.53it/s]\n",
      "Processing 'M': 100%|██████████| 900/900 [00:31<00:00, 28.44it/s]\n",
      "Processing 'N': 100%|██████████| 900/900 [00:34<00:00, 26.00it/s]\n",
      "Processing 'O': 100%|██████████| 900/900 [00:33<00:00, 27.19it/s]\n",
      "Processing 'P': 100%|██████████| 900/900 [00:39<00:00, 22.95it/s]\n",
      "Processing 'Q': 100%|██████████| 900/900 [00:31<00:00, 28.76it/s]\n",
      "Processing 'R': 100%|██████████| 900/900 [00:32<00:00, 27.29it/s]\n",
      "Processing 'S': 100%|██████████| 900/900 [00:32<00:00, 27.54it/s]\n",
      "Processing 'T': 100%|██████████| 900/900 [00:33<00:00, 26.59it/s]\n",
      "Processing 'U': 100%|██████████| 900/900 [00:32<00:00, 27.41it/s]\n",
      "Processing 'V': 100%|██████████| 900/900 [00:26<00:00, 33.98it/s]\n",
      "Processing 'W': 100%|██████████| 900/900 [00:29<00:00, 30.35it/s]\n",
      "Processing 'X': 100%|██████████| 900/900 [00:25<00:00, 35.37it/s]\n",
      "Processing 'Y': 100%|██████████| 900/900 [00:25<00:00, 35.68it/s]\n",
      "Processing 'Z': 100%|██████████| 900/900 [00:25<00:00, 35.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp\n",
    "\n",
    "dataset_path = r'C:\\Users\\moham\\Downloads\\Robotech\\Summer_Training\\Project\\Note_Book\\Train_data'\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "label_dict = {}  \n",
    "\n",
    "all_folders = sorted(os.listdir(dataset_path))\n",
    "\n",
    "for idx, folder in enumerate(all_folders):\n",
    "    label_dict[idx] = folder.upper()\n",
    "\n",
    "for idx, folder in enumerate(all_folders):\n",
    "    \n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "    label = folder.upper()\n",
    "\n",
    "    for file in tqdm(os.listdir(folder_path), desc=f\"Processing '{label}'\"):\n",
    "        \n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(img_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                x_ = []\n",
    "                y_ = []\n",
    "                features = []\n",
    "\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    x_.append(lm.x)\n",
    "                    y_.append(lm.y)\n",
    "\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    features.append(lm.x - min(x_))\n",
    "                    features.append(lm.y - min(y_))\n",
    "\n",
    "                if len(features) == 42:\n",
    "                    data.append(features)\n",
    "                    labels.append(idx)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = len(label_dict)\n",
    "labels_cat = to_categorical(labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels_cat, test_size=0.2, random_state=42, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afd4b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(42,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df805258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,         \n",
    "    restore_best_weights=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a013295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2930 - loss: 2.3276 - val_accuracy: 0.9036 - val_loss: 0.4636\n",
      "Epoch 2/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8557 - loss: 0.4905 - val_accuracy: 0.9633 - val_loss: 0.2097\n",
      "Epoch 3/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9213 - loss: 0.2767 - val_accuracy: 0.9761 - val_loss: 0.1501\n",
      "Epoch 4/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2178 - val_accuracy: 0.9674 - val_loss: 0.1473\n",
      "Epoch 5/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1676 - val_accuracy: 0.9780 - val_loss: 0.1094\n",
      "Epoch 6/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9655 - loss: 0.1510 - val_accuracy: 0.9805 - val_loss: 0.0943\n",
      "Epoch 7/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9637 - loss: 0.1483 - val_accuracy: 0.9821 - val_loss: 0.0939\n",
      "Epoch 8/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.1319 - val_accuracy: 0.9824 - val_loss: 0.0812\n",
      "Epoch 9/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.1216 - val_accuracy: 0.9831 - val_loss: 0.0752\n",
      "Epoch 10/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9795 - loss: 0.0919 - val_accuracy: 0.9852 - val_loss: 0.0737\n",
      "Epoch 11/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9756 - loss: 0.1057 - val_accuracy: 0.9815 - val_loss: 0.0755\n",
      "Epoch 12/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9745 - loss: 0.1006 - val_accuracy: 0.9859 - val_loss: 0.0608\n",
      "Epoch 13/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9812 - loss: 0.0804 - val_accuracy: 0.9865 - val_loss: 0.0639\n",
      "Epoch 14/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9819 - loss: 0.0850 - val_accuracy: 0.9852 - val_loss: 0.0598\n",
      "Epoch 15/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0787 - val_accuracy: 0.9849 - val_loss: 0.0685\n",
      "Epoch 16/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0691 - val_accuracy: 0.9871 - val_loss: 0.0593\n",
      "Epoch 17/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0679 - val_accuracy: 0.9884 - val_loss: 0.0471\n",
      "Epoch 18/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9854 - loss: 0.0599 - val_accuracy: 0.9893 - val_loss: 0.0460\n",
      "Epoch 19/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0744 - val_accuracy: 0.9896 - val_loss: 0.0467\n",
      "Epoch 20/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0632 - val_accuracy: 0.9890 - val_loss: 0.0505\n",
      "Epoch 21/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9832 - loss: 0.0659 - val_accuracy: 0.9887 - val_loss: 0.0508\n",
      "Epoch 22/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9830 - loss: 0.0563 - val_accuracy: 0.9874 - val_loss: 0.0520\n",
      "Epoch 23/300\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0554 - val_accuracy: 0.9884 - val_loss: 0.0474\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cfa58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9882 - loss: 0.0661  \n",
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2970186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "model.save(\"asl_mlp_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3272e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab={}\n",
    "all_folders = sorted(os.listdir(dataset_path))\n",
    "\n",
    "for idx, folder in enumerate(all_folders):\n",
    "    lab[idx] = folder.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cea52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"label_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lab, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
